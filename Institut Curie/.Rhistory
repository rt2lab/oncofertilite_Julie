install.packages('survival')
library(survival)
install.packages('survminer')
library(survminer)
library(survMisc)
survreg?
survreg??
help("survreg")
help(survreg)
survival <-survreg(Duration~Revenue + Employees + Acq_Expense_SQ + Acq_Expense+ Industry, data=ac,dist="weibull" )
# Create data frame "ac" from CSV file w/headers
ac<-read.csv(file.choose(), header = TRUE,sep = ";", quote = "\"" )
View(ac)
View(ac)
ac<-read.csv(file.choose(), header = TRUE,sep = ";", quote = "\"" )
ac<-read.csv(file.choose(), header = TRUE,sep = ";", quote = "\"" )
# Take home exam quantitative marketing
# Part one: customer acquisition
# Create data frame "ac" from CSV file w/headers
ac<-read.csv(file.choose(), header = TRUE,sep = ";", quote = "\"" )
# replace character by numeric variables
# First we need to convert "," to "."
ac$First_Purchase <- gsub(",",".",ac$First_Purchase)
ac$First_Purchase <- as.numeric(ac$First_Purchase)
summary(ac$First_Purchase)
ac$CLV <- gsub(",",".",ac$CLV)
ac$Acq_Expense <- gsub(",",".",ac$Acq_Expense)
ac$Acq_Expense_SQ <- gsub(",",".",ac$Acq_Expense_SQ)
ac$Revenue <- gsub(",",".",ac$Revenue)
ac$Ret_Expense <- gsub(",",".",ac$Ret_Expense)
ac$Ret_Expense_SQ <- gsub(",",".",ac$Ret_Expense_SQ)
ac[sapply(ac, is.character)] <- lapply(ac[sapply(ac, is.character)], as.numeric)
str(ac)
# so now we have only int and num variables
summary(ac)
#question 6
install.packages('survival')
library(survival)
ac2 <- subset(ac, Duration != 0)
ac2$logDur<-log(ac2$Duration)
survival<-survreg(Surv(logDur,Censor) ~ Revenue + Employees + Acq_Expense_SQ + Acq_Expense+ Industry + Crossbuy + Ret_Expense_SQ + Ret_Expense + Frequency + Frequency_SQ, data=ac2, dist='weibull', scale=1, control = list(maxiter=100))
survival
#prÃ©diction des valeurs
predictionsur<-predict(survival, ac,
type=c("response", "link", "lp", "linear", "terms", "quantile",
"uquantile"),
se.fit=FALSE, terms=NULL, p=c(0.1, 0.9), na.action=na.pass)
predictionsur
#MAD
mean(abs(ac$predictionsur-ac$Duration))
mean(abs((ac$predictionsur-ac$Duration)/ac$Duration))
# Partie 2 :
# Create data frame "ac" from CSV file w/headers
ret<-read.csv(file.choose(), header = TRUE,sep = ";", quote = "\"" )
install.packages("aod")
install.packages("ggplot2")
install.packages("psych")
install.packages("stargazer")
install.packages("xtable")
install.packages("sampleSelection")
library(aod)
library(ggplot2)
library(psych)
library(stargazer)
library(xtable)
library(sampleSelection)
View(ret)
myprobit <- glm(Acquisition ~ Revenue + Employees + Acq_Expense + Acq_Expense_SQ + Industry, data = ret, family= binomial(link = "probit"))
summary(myprobit)
myprobit <- glm(Acquisition ~ Revenue + Employees + Acq_Exp + Acq_Exp_SQ + Industry, data = ret, family= binomial(link = "probit"))
summary(myprobit)
confint(myprobit)
B0 <- coef(summary(myprobit))["(Intercept)","Estimate"]
BRev <- coef(summary(myprobit))["Revenue","Estimate"]
BEmpl <- coef(summary(myprobit))["Employees","Estimate"]
BAcq <- coef(summary(myprobit))["Acq_Exp","Estimate"]
BAcqsq <- coef(summary(myprobit))["Acq_Exp_SQ","Estimate"]
Bind <- coef(summary(myprobit))["Industry","Estimate"]
#MAD
mean(abs(ac$predictionsur-ac$Duration))
#MAPE
mean(abs((ac$predictionsur-ac$Duration)/ac$Duration))
summary(predictionsur)
#MAD
mean(abs(ac2$predictionsur-ac2$Duration))
myprobit <- glm(Acquisition ~ Revenue + Employees + Acq_Exp + Acq_Exp_SQ + Industry, data = ret, family= binomial(link = "probit"))
summary(myprobit)
myprobit <- glm(Acquisition ~ Revenue + Employees + Acq_Exp + Industry, data = ret, family= binomial(link = "probit"))
summary(myprobit)
ret$Ret_Exp <- gsub(",",".",ret$Ret_Exp)
ret$Ret_Exp <- as.numeric(ret$Ret_Exp)
summary(ret$Ret_Exp)
ret$Profit <- gsub(",",".",ret$Profit)
ret$Acq_Exp <- gsub(",",".",ret$Acq_Exp)
ret$Acq_Exp_SQ <- gsub(",",".",ret$Acq_Exp_SQ)
ret$Ret_Exp_SQ <- gsub(",",".",ret$Ret_Exp_SQ)
ret$Revenue <- gsub(",",".",ret$Revenue)
ret[sapply(ret, is.character)] <- lapply(ret[sapply(ret, is.character)], as.numeric)
str(ret)
# so now we have only int and num variables
summary(ret)
# estimating logit model "myprobit"
myprobit <- glm(Acquisition ~ Revenue + Employees + Acq_Exp + Acq_Exp_SQ + Industry, data = ret, family= binomial(link = "probit"))
summary(myprobit)
B0 <- coef(summary(myprobit))["(Intercept)","Estimate"]
BRev <- coef(summary(myprobit))["Revenue","Estimate"]
BEmpl <- coef(summary(myprobit))["Employees","Estimate"]
BAcq <- coef(summary(myprobit))["Acq_Exp","Estimate"]
BAcqsq <- coef(summary(myprobit))["Acq_Exp_SQ","Estimate"]
Bind <- coef(summary(myprobit))["Industry","Estimate"]
stargazer(myprobit, title="Probit output",align=TRUE, covariate.labels=c("Revenue","Employees","Acq_Expense","Acq_Expense_SQ","Industry"),omit.stat=c("LL","ser"), no.space=TRUE)
# Signs of the coefficient are as expected : positive for Revenue, Employees.
# Sign of quadratic acquisition expenses is negative, suggesting an inverted u pattern
# Industry dummy is significant and positive this time, suggesting belonging to B2B positively affects customer acquisition
wald.test(b = coef(myprobit), Sigma = vcov(myprobit), Terms = 4:5)
# Wald test for the joint null hypothesis of coefficients of Acqu_Expenses
wald.test(b = coef(myprobit), Sigma = vcov(myprobit), Terms = 2:6)
# Wald test for the joint null hypothesis of all coefficients of interest
stargazer(survival, title="Survreg output",align=TRUE, covariate.labels=c("Revenue","Employees","Acq_Expense_SQ","Acq_Expense","Industry","Crossbuy", "Ret_expense_SQ", "Ret_Expense", "Frequency", "Frequency_SQ"),omit.stat=c("LL","ser"), no.space=TRUE)
stargazer(predictionsur, title="Survreg output",align=TRUE,omit.stat=c("LL","ser"), no.space=TRUE)
ret2 <- subset(ret, Duration != 0)
ret2$logDur<-log(ret2$Duration)
olsDur <- lm(logDur ~ Revenue + Employees+ Ret_Exp+ Ret_Exp_SQ + Industry, data=subset(ret2,Acquisition==1))
summary(olsDur)
stargazer(olsDur, title="Ols output",align=TRUE, covariate.labels=c("Revenue","Ret_Exp","Ret_Exp_Sq","Industry"),omit.stat=c("LL","ser"), no.space=TRUE)
# we compute the Inverse Mills Ratio
ret2$probret <- predict(myprobit, newdata = ret2)
ret2$imr <- dnorm(ret2$myprobit)/pnorm(ret2$myprobit)
# we compute the Inverse Mills Ratio
ret2$probret <- predict(myprobit, newdata = ret2)
ret2$imr <- dnorm(ret2$probret)/pnorm(ret2$probret)
# We will run the ols stage only when First_Purchase is different from 0
retacqu1 <- subset(ret2,Acquisition==1)
olsfin <- lm(logDur ~ Revenue + Employees+ Ret_Exp+ Ret_Exp_SQ + Industry + imr, data=retacqu1)
summary(olsfin)
stargazer(olsfin, ols3, title=" Heckman two-step")
stargazer(myprobit,olsfin, title=" Heckman two-step")
#predict
ret2$probretob <- predict(olsfin, newdata = ret2)
olsprofit <- lm(probretob ~ Revenue + Employees + Industry  , data=retacqu1)
ret2$probretob <- predict(olsfin, newdata = ret2)
olsprofit <- lm(probretob ~ Revenue + Employees + Industry  , data=retacqu1)
summary(olsprofit)
olsprofit <- lm(ret2$probretob ~ Revenue + Employees + Industry  , data=retacqu1)
summary(olsprofit)
stargazer(olsprofit, title="OLS profit",align=TRUE, covariate.labels=c("Revenue","Employees","Industry"),omit.stat=c("LL","ser"), no.space=TRUE)
stargazer(olsprofit, title="OLS profit",align=TRUE, covariate.labels=c("Revenue","Employees","Industry"),omit.stat=c("LL","ser"), no.space=TRUE)
olsDur <- lm(logDur ~ Revenue + Employees+ Ret_Exp+ Ret_Exp_SQ + Industry+Freq + Freq_SQ , data=subset(ret2,Acquisition==1))
summary(olsDur)
# we compute the Inverse Mills Ratio
ret2$probret <- predict(myprobit, newdata = ret2)
ret2$imr <- dnorm(ret2$probret)/pnorm(ret2$probret)
# We will run the ols stage only when Fir
# We will run the ols stage only when First_Purchase is different from 0
retacqu1 <- subset(ret2,Acquisition==1)
# We run the ols stage and find a statistically significant Mills ratio at the 10% level (biais present
# in the ols results).
olsfin <- lm(logDur ~ Revenue + Employees+ Ret_Exp+ Ret_Exp_SQ + Industry + imr, data=retacqu1)
summary(olsfin)
olsprofit <- lm(ret2$probretob ~ Revenue + Employees + Industry + Freq + Freq_SQ + SOW + Crossbuy , data=retacqu1)
summary(olsprofit)
olsprofit <- lm(Profit ~ Revenue + Employees + Industry + Freq + Freq_SQ + SOW + Crossbuy + ret2$probretob , data=retacqu1)
summary(olsprofit)
stargazer(olsprofit, title="OLS profit",align=TRUE, covariate.labels=c("Revenue","Employees","Industry"),omit.stat=c("LL","ser"), no.space=TRUE)
# We run the ols stage and find a statistically significant Mills ratio at the 10% level (biais present
# in the ols results).
olsfin <- lm(logDur ~ Revenue + Employees+ Ret_Exp+ Ret_Exp_SQ + Freq + Freq_SQ+ Industry + imr, data=retacqu1)
summary(olsfin)
stargazer(myprobit,olsfin, title=" Heckman two-step")
#predict
ret2$probretob <- predict(olsfin, newdata = ret2)
#question 11
olsprofit <- lm(Profit ~ Revenue + Employees + Industry + Freq + Freq_SQ + SOW + Crossbuy + ret2$probretob , data=retacqu1)
summary(olsprofit)
stargazer(olsprofit, title="OLS profit",align=TRUE, covariate.labels=c("Revenue","Employees","Industry"),omit.stat=c("LL","ser"), no.space=TRUE)
# estimating logit model "myprobit"
myprobit <- glm(Acquisition ~ Revenue + Employees + Acq_Exp + Acq_Exp_SQ + Industry, data = ret, family= binomial(link = "probit"))
summary(myprobit)
wald.test(b = coef(myprobit), Sigma = vcov(myprobit), Terms = 4:5)
# Wald test for the joint null hypothesis of coefficients of Acqu_Expenses
wald.test(b = coef(myprobit), Sigma = vcov(myprobit), Terms = 2:6)
# Wald test for the joint null hypothesis of all coefficients of interest
# First we run the ols regression (endogeneous: Duration)
olsDur <- lm(logDur ~ Revenue + Employees+ Ret_Exp+ Ret_Exp_SQ + Industry+Freq + Freq_SQ , data=subset(ret2,Acquisition==1))
summary(olsDur)
#question 11
olsprofit <- lm(Profit ~ Revenue + Employees + Industry + Freq + Freq_SQ + SOW + Crossbuy + ret2$probretob , data=retacqu1)
summary(olsprofit)
# estimating logit model "myprobit"
myprobit <- glm(Acquisition ~ Revenue + Employees + Acq_Exp + Acq_Exp_SQ + Industry, data = ret, family= binomial(link = "probit"))
summary(myprobit)
stargazer(myprobit, title="Probit output",align=TRUE, covariate.labels=c("Revenue","Employees","Acq_Expense","Acq_Expense_SQ","Industry"),omit.stat=c("LL","ser"), no.space=TRUE)
# First we run the ols regression (endogeneous: Duration)
olsDur <- lm(logDur ~ Revenue + Employees+ Ret_Exp+ Ret_Exp_SQ + Industry+Freq + Freq_SQ , data=subset(ret2,Acquisition==1))
summary(olsDur)
stargazer(olsDur, title="Ols output",align=TRUE, covariate.labels=c("Revenue","Ret_Exp","Ret_Exp_Sq","Industry"),omit.stat=c("LL","ser"), no.space=TRUE)
# we compute the Inverse Mills Ratio
ret2$probret <- predict(myprobit, newdata = ret2)
ret2$imr <- dnorm(ret2$probret)/pnorm(ret2$probret)
# We will run the ols stage only when First_Purchase is different from 0
retacqu1 <- subset(ret2,Acquisition==1)
# We run the ols stage and find a statistically significant Mills ratio at the 10% level (biais present
# in the ols results).
olsfin <- lm(logDur ~ Revenue + Employees+ Ret_Exp+ Ret_Exp_SQ + Freq + Freq_SQ+ Industry + imr, data=retacqu1)
summary(olsfin)
stargazer(myprobit,olsfin, title=" Heckman two-step")
olsprofit <- lm(Profit ~ Revenue + Employees + Industry + Freq + Freq_SQ + SOW + Crossbuy + ret2$probretob , data=retacqu1)
summary(olsprofit)
stargazer(olsprofit, title="OLS profit",align=TRUE, covariate.labels=c("Revenue","Employees","Industry"),omit.stat=c("LL","ser"), no.space=TRUE)
olsfin <- lm(logDur ~ Revenue + Employees+ Ret_Exp+ Ret_Exp_SQ + Freq + Freq_SQ+ Industry + imr, data=retacqu1)
summary(olsfin)
install.packages('survival')
library(survival)
ac2 <- subset(ac, Duration != 0)
ac2$logDur<-log(ac2$Duration)
survival<-survreg(Surv(logDur,Censor) ~ Revenue + Employees + Acq_Expense_SQ + Acq_Expense+ Industry + Crossbuy + Ret_Expense_SQ + Ret_Expense + Frequency + Frequency_SQ, data=ac2, dist='weibull', scale=1, control = list(maxiter=100))
stargazer(survival, title="Survreg output",align=TRUE, covariate.labels=c("Revenue","Employees","Acq_Expense_SQ","Acq_Expense","Industry","Crossbuy", "Ret_expense_SQ", "Ret_Expense", "Frequency", "Frequency_SQ"),omit.stat=c("LL","ser"), no.space=TRUE)
survival
install.packages("survival")
confint.default(survival)
exp(cbind(OR = coef(survival), confint(survival)))
exptab <- exp(cbind(OR = coef(survival), confint(survival)))
stargazer(exptab, title="AFT output",align=TRUE, covariate.labels=c("Revenue","Employees","Acq_Expense","Acq_Expense_SQ","Industry"),omit.stat=c("LL","ser"), no.space=TRUE)
confint.default(survival)
exp(cbind(coef(survival), confint(survival)))
exptab <- exp(cbind( coef(survival), confint(survival)))
stargazer(exptab, title="AFT output",align=TRUE, covariate.labels=c("Revenue","Employees","Acq_Expense","Acq_Expense_SQ","Industry"),omit.stat=c("LL","ser"), no.space=TRUE)
exp(coef(survival))
exptab <- exp(coef(survival))
stargazer(exptab, title="AFT output",align=TRUE, covariate.labels=c("Revenue","Employees","Acq_Expense","Acq_Expense_SQ","Industry"),omit.stat=c("LL","ser"), no.space=TRUE)
stargazer(exptab, title="AFT output",align=FALSE, covariate.labels=c("Revenue","Employees","Acq_Expense","Acq_Expense_SQ","Industry"), no.space=TRUE)
# Take home exam quantitative marketing
# Part one: customer acquisition
# Create data frame "ac" from CSV file w/headers
ac<-read.csv(file.choose(), header = TRUE,sep = ";", quote = "\"" )
load("C:/Users/Julie/Downloads/07_oncofertilite_consore_preprocessed_labels.RData")
load("C:/Users/Julie/Desktop/Institut Curie/07_oncofertilite_consore_preprocessed_labels.RData")
data_dir = 'data/'
data = read.csv("C:\Users\Julie\Desktop\Institut Curie\07_oncofertilite_consore_preprocessed_labels.csv")
data = read.csv("C:/Users/Julie/Desktop/Institut Curie/07_oncofertilite_consore_preprocessed_labels.csv")
######################## Time-to-pregnancy project###################
#### On utilise la base oncofertilite_consore... C:\Users\Julie\Desktop\Institut Curie\07_oncofertilite_consore_preprocessed_labels.csv
setwd(dir ="C:/Users/Julie/Desktop/Institut Curie/")
data_dir = 'data/'
## tÃ©lÃ©chargement de la base de donnÃ©es
data = read.csv("C:/Users/Julie/Desktop/Institut Curie/07_oncofertilite_consore_preprocessed_labels.csv")
data = read.csv2("C:/Users/Julie/Desktop/Institut Curie/07_oncofertilite_consore_preprocessed_labels.csv")
View(data)
View(data)
summary(data)
library(tidyverse)
#library
install.packages(tidyverse)
#library
install.packages('tidyverse')
